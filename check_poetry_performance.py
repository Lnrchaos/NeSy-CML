#!/usr/bin/env python3
"""
Check the actual performance metrics of the poetry model
"""

import torch
import json

def check_poetry_performance():
    """Check the detailed performance of the poetry model"""
    print("ğŸ­ Poetry Model Performance Analysis")
    print("=" * 50)
    
    try:
        # Load the model checkpoint
        checkpoint = torch.load("best_poetry_model_optimized.pt", map_location='cpu', weights_only=False)
        
        print(f"ğŸ“Š Training Information:")
        print(f"   Epochs completed: {checkpoint.get('epoch', 'Unknown')}")
        print(f"   Model classes: {checkpoint['config']['num_classes']}")
        
        # Check creativity score
        if 'creativity_score' in checkpoint:
            creativity = checkpoint['creativity_score']
            print(f"   Creativity Score: {creativity}")
        
        # Check poetry metrics
        if 'poetry_metrics' in checkpoint:
            metrics = checkpoint['poetry_metrics']
            print(f"\nğŸ¯ Poetry Metrics:")
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    print(f"   {key}: {value:.4f}")
                else:
                    print(f"   {key}: {value}")
        
        # Check training history
        if 'training_history' in checkpoint:
            history = checkpoint['training_history']
            print(f"\nğŸ“ˆ Training History:")
            if isinstance(history, list) and len(history) > 0:
                last_epoch = history[-1]
                print(f"   Last epoch metrics: {last_epoch}")
            else:
                print(f"   Training history: {history}")
        
        # Overall assessment
        print(f"\nğŸ¯ RELEASE WORTHINESS DECISION:")
        
        # Check if we have enough training
        epochs = checkpoint.get('epoch', 0)
        if epochs < 5:
            print(f"   âš ï¸  Only {epochs} epoch(s) trained - might be undertrained")
            print(f"   ğŸ’¡ Recommendation: Train for more epochs before release")
            return False
        
        # Check if we have performance metrics
        has_metrics = 'poetry_metrics' in checkpoint or 'creativity_score' in checkpoint
        if not has_metrics:
            print(f"   âš ï¸  No clear performance metrics found")
            print(f"   ğŸ’¡ Recommendation: Evaluate model performance first")
            return False
        
        # If we have creativity score, check if it's reasonable
        if 'creativity_score' in checkpoint:
            creativity = checkpoint['creativity_score']
            if creativity > 0.5:
                print(f"   âœ… Good creativity score: {creativity:.3f}")
                print(f"   ğŸ‰ Model appears release-worthy!")
                return True
            else:
                print(f"   âš ï¸  Low creativity score: {creativity:.3f}")
                print(f"   ğŸ’¡ Recommendation: Improve training before release")
                return False
        
        print(f"   â“ Unable to determine quality - need more evaluation")
        return False
        
    except Exception as e:
        print(f"âŒ Error analyzing model: {e}")
        return False

def release_recommendations():
    """Provide specific recommendations for release"""
    print(f"\nğŸ’¡ RELEASE RECOMMENDATIONS:")
    print(f"   ğŸ“Š For GitHub Release, your model should have:")
    print(f"   âœ… F1 scores > 0.4 for main poetry categories")
    print(f"   âœ… Creativity score > 0.5")
    print(f"   âœ… At least 10+ training epochs")
    print(f"   âœ… Coherent poetry generation capability")
    
    print(f"\nğŸ¯ CURRENT STATUS:")
    print(f"   Chess Model: âœ… Ready (83.94% accuracy, 25 epochs)")
    print(f"   Poetry Model: â“ Needs evaluation")
    
    print(f"\nğŸ“ SUGGESTED APPROACH:")
    print(f"   1. ğŸš€ Release chess model immediately (excellent performance)")
    print(f"   2. ğŸ§ª Test poetry model more thoroughly")
    print(f"   3. ğŸ­ If poetry model performs well, release as v1.1")
    print(f"   4. ğŸ“ˆ If not, train longer and release later")

if __name__ == "__main__":
    is_worthy = check_poetry_performance()
    release_recommendations()
    
    if is_worthy:
        print(f"\nğŸ‰ VERDICT: Poetry model is RELEASE WORTHY! ğŸš€")
    else:
        print(f"\nâ³ VERDICT: Hold off on poetry model release for now")